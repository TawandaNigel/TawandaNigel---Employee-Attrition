{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a15216b",
   "metadata": {},
   "source": [
    "### Project: Understanding Employee Attrition with Machine Learning \n",
    "### Activity: Logistic Regression - Model Evaluation on Up Sampled Data\n",
    "### Model: Logistic Regression\n",
    "### Author: Tawanda Nigel Chitapi\n",
    "### Email: nigel.chitapi@gmail.com    \n",
    "### Date: September 05, 2022\n",
    "### Institution: BrainStation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826ca637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# the data science trinity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# model selection tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, roc_curve, roc_auc_score\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e07d6",
   "metadata": {},
   "source": [
    "The goal of this notebook is to perform upsampling on the the training data in order to solve the problem of imbalanced attrition classes. After balancing the data we will then re-instatiate the logistic regression model, evaluate the model and compare the results with those of the unsampled data.\n",
    "\n",
    "The work-flow will be similar to that of the Unsampled data notebook for ease of flowing the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data \n",
    "\n",
    "employee_df = pd.read_csv('data/employee_attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845b5e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>Other</th>\n",
       "      <th>Technical Degree</th>\n",
       "      <th>Admin</th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Nurse</th>\n",
       "      <th>Other.1</th>\n",
       "      <th>Therapist</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married</th>\n",
       "      <th>Single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313919</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200302</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060315</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272912</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1414939</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  Age  Attrition  DailyRate  DistanceFromHome  Education  \\\n",
       "0     1313919   41          0       1102                 1          2   \n",
       "1     1200302   49          0        279                 8          1   \n",
       "2     1060315   37          1       1373                 2          2   \n",
       "3     1272912   33          0       1392                 3          4   \n",
       "4     1414939   27          0        591                 2          1   \n",
       "\n",
       "   EmployeeCount  EnvironmentSatisfaction  Gender  HourlyRate  ...  Other  \\\n",
       "0              1                        2       1          94  ...      0   \n",
       "1              1                        3       0          61  ...      0   \n",
       "2              1                        4       0          92  ...      1   \n",
       "3              1                        4       1          56  ...      0   \n",
       "4              1                        1       0          40  ...      0   \n",
       "\n",
       "   Technical Degree  Admin  Administrative  Nurse  Other.1  Therapist  \\\n",
       "0                 0      0               0      1        0          0   \n",
       "1                 0      0               0      0        1          0   \n",
       "2                 0      0               0      1        0          0   \n",
       "3                 0      0               0      0        1          0   \n",
       "4                 0      0               0      1        0          0   \n",
       "\n",
       "   Divorced  Married  Single  \n",
       "0         0        0       1  \n",
       "1         0        1       0  \n",
       "2         0        0       1  \n",
       "3         0        1       0  \n",
       "4         0        1       0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to see if our data loaded successfully\n",
    "\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee3b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1676 entries, 0 to 1675\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   EmployeeID                1676 non-null   int64\n",
      " 1   Age                       1676 non-null   int64\n",
      " 2   Attrition                 1676 non-null   int64\n",
      " 3   DailyRate                 1676 non-null   int64\n",
      " 4   DistanceFromHome          1676 non-null   int64\n",
      " 5   Education                 1676 non-null   int64\n",
      " 6   EmployeeCount             1676 non-null   int64\n",
      " 7   EnvironmentSatisfaction   1676 non-null   int64\n",
      " 8   Gender                    1676 non-null   int64\n",
      " 9   HourlyRate                1676 non-null   int64\n",
      " 10  JobInvolvement            1676 non-null   int64\n",
      " 11  JobLevel                  1676 non-null   int64\n",
      " 12  JobSatisfaction           1676 non-null   int64\n",
      " 13  MonthlyIncome             1676 non-null   int64\n",
      " 14  MonthlyRate               1676 non-null   int64\n",
      " 15  NumCompaniesWorked        1676 non-null   int64\n",
      " 16  Over18                    1676 non-null   int64\n",
      " 17  OverTime                  1676 non-null   int64\n",
      " 18  PercentSalaryHike         1676 non-null   int64\n",
      " 19  PerformanceRating         1676 non-null   int64\n",
      " 20  RelationshipSatisfaction  1676 non-null   int64\n",
      " 21  StandardHours             1676 non-null   int64\n",
      " 22  Shift                     1676 non-null   int64\n",
      " 23  TotalWorkingYears         1676 non-null   int64\n",
      " 24  TrainingTimesLastYear     1676 non-null   int64\n",
      " 25  WorkLifeBalance           1676 non-null   int64\n",
      " 26  YearsAtCompany            1676 non-null   int64\n",
      " 27  YearsInCurrentRole        1676 non-null   int64\n",
      " 28  YearsSinceLastPromotion   1676 non-null   int64\n",
      " 29  YearsWithCurrManager      1676 non-null   int64\n",
      " 30  Non-Travel                1676 non-null   int64\n",
      " 31  Travel_Frequently         1676 non-null   int64\n",
      " 32  Travel_Rarely             1676 non-null   int64\n",
      " 33  Cardiology                1676 non-null   int64\n",
      " 34  Maternity                 1676 non-null   int64\n",
      " 35  Neurology                 1676 non-null   int64\n",
      " 36  Human Resources           1676 non-null   int64\n",
      " 37  Life Sciences             1676 non-null   int64\n",
      " 38  Marketing                 1676 non-null   int64\n",
      " 39  Medical                   1676 non-null   int64\n",
      " 40  Other                     1676 non-null   int64\n",
      " 41  Technical Degree          1676 non-null   int64\n",
      " 42  Admin                     1676 non-null   int64\n",
      " 43  Administrative            1676 non-null   int64\n",
      " 44  Nurse                     1676 non-null   int64\n",
      " 45  Other.1                   1676 non-null   int64\n",
      " 46  Therapist                 1676 non-null   int64\n",
      " 47  Divorced                  1676 non-null   int64\n",
      " 48  Married                   1676 non-null   int64\n",
      " 49  Single                    1676 non-null   int64\n",
      "dtypes: int64(50)\n",
      "memory usage: 654.8 KB\n"
     ]
    }
   ],
   "source": [
    "employee_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3191d096",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'employee_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dy/wqzw4m_d6wlg5ksm4mv43lz00000gn/T/ipykernel_3315/4085275161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memployee_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memployee_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'employee_df' is not defined"
     ]
    }
   ],
   "source": [
    "# features\n",
    "X = employee_df.drop('Attrition', axis=1)\n",
    "\n",
    "# target\n",
    "y = employee_df['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7f3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.3,\n",
    "    stratify = y,\n",
    "    random_state = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad19b5f",
   "metadata": {},
   "source": [
    "We have initiated an 70% train set and 30% test set split on our data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701cafab",
   "metadata": {},
   "source": [
    "Our dataset contains 50 columns, with the amount of data that we have (1676 rows), 50 columns are too wide a dimension puts our model at the risk of the curse of dimensionality. After we conducted feature engineering during data cleaning and processing, the number of features in our dataset incresed from 35 to 50.\n",
    "In order to best predict our target variable we need to conduct some feature selection and select only those variables that best predict out target variable.\n",
    "To achieve this we will use the Fisher - Chi-Squared test and assess the derived p-values to select on the best predictor with p-values less than the threshold of 0.05.\n",
    "The Fisher - Chi-Squared test is applied on the training data because the selected features are used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50f8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31986259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.21143359e+03, 2.18075488e+02, 9.80042735e+02, 1.34752206e+02,\n",
       "        9.14675779e-01, 0.00000000e+00, 7.62324266e+00, 4.26023102e-01,\n",
       "        1.37660534e+01, 8.64185842e+00, 4.33138845e+01, 4.99790687e+00,\n",
       "        2.15238646e+05, 1.25027767e+04, 1.15322155e+00, 0.00000000e+00,\n",
       "        1.36592523e+02, 1.26983331e-02, 7.82147747e-03, 2.99901161e-01,\n",
       "        0.00000000e+00, 3.81226029e+01, 4.97310855e+02, 2.98027378e+00,\n",
       "        2.44735458e+00, 3.59223808e+02, 2.23346033e+02, 5.90028751e+01,\n",
       "        2.07527896e+02, 1.08669784e+00, 1.07867314e+01, 1.71639456e+00,\n",
       "        2.15864231e+00, 1.45973417e-01, 5.70868185e+00, 2.15412094e+00,\n",
       "        2.11386774e-02, 1.56263236e+00, 2.29483170e+00, 6.51176112e-01,\n",
       "        1.19062460e+00, 2.15572106e+00, 1.33078829e+01, 1.02725034e+00,\n",
       "        9.96392145e+00, 1.71956394e+01, 1.09284509e+01, 1.20169006e+01,\n",
       "        4.95438134e+01]),\n",
       " array([1.99742170e-265, 2.37780925e-049, 3.91110641e-215, 3.74056454e-031,\n",
       "        3.38876833e-001, 1.00000000e+000, 5.76207893e-003, 5.13946832e-001,\n",
       "        2.07043843e-004, 3.28526142e-003, 4.66263191e-011, 2.53779918e-002,\n",
       "        0.00000000e+000, 0.00000000e+000, 2.82875781e-001, 1.00000000e+000,\n",
       "        1.48051863e-031, 9.10278803e-001, 9.29527672e-001, 5.83944390e-001,\n",
       "        1.00000000e+000, 6.64360504e-010, 3.65659657e-110, 8.42850144e-002,\n",
       "        1.17723119e-001, 4.15525833e-080, 1.68481749e-050, 1.57441751e-014,\n",
       "        4.75580191e-047, 2.97204021e-001, 1.02230239e-003, 1.90157807e-001,\n",
       "        1.41769907e-001, 7.02413392e-001, 1.68812104e-002, 1.42187800e-001,\n",
       "        8.84401805e-001, 2.11280207e-001, 1.29805281e-001, 4.19692502e-001,\n",
       "        2.75203604e-001, 1.42039749e-001, 2.64292606e-004, 3.10805360e-001,\n",
       "        1.59637668e-003, 3.37209504e-005, 9.46986434e-004, 5.27203008e-004,\n",
       "        1.93990632e-012]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_p_values = chi2(X, y)\n",
    "\n",
    "f_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efa3ad",
   "metadata": {},
   "source": [
    "The variable **f_p_values** refers to f-score, p-value values, the first array [0] represents f-scores and the second array [1] represent the p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a59f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series of p_values and match them to the relevant columns \n",
    "\n",
    "p_values = pd.Series(f_p_values[1],index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b96e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the p_values in descending order \n",
    "p_values.sort_values(ascending = False , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06446a",
   "metadata": {},
   "source": [
    "Plot a bar graph of the column and relevant p_values to better identify and select preferred columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a850b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'None'}>], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a bar graph\n",
    "p_values.plot.barh(figsize= (25,30), subplots=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e97ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newly Updated features\n",
    "X = employee_df[['Age','DailyRate', 'DistanceFromHome', 'JobLevel','OverTime','Single',\n",
    "               'Shift','TotalWorkingYears','Therapist', 'MonthlyRate', 'HourlyRate',\n",
    "                 'YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion',\n",
    "                 'YearsWithCurrManager','Travel_Frequently','Married', 'Divorced',\n",
    "                 'Administrative']]\n",
    "\n",
    "# target\n",
    "y = employee_df['Attrition']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def569f8",
   "metadata": {},
   "source": [
    "After observing the results from the plot above, we have selected features with p_value less than 0.05 as these will best predict our target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556d1c6",
   "metadata": {},
   "source": [
    "#### We will upsample our data using the SMOTE, an algorithm that performs data augmentation by creating synthetic data points based on the original data points. This will be instatiated and fit on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b76066e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SMOTE sampler, fit it to the training data, then resample the data\n",
    "X_train_sm, y_train_sm = SMOTE(random_state=1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822b1056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1034\n",
       "1     139\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled class distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1034\n",
       "1    1034\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check to see what SMOTE has done\n",
    "\n",
    "print('Original class distribution')\n",
    "display(pd.Series(y_train).value_counts().sort_index())\n",
    "\n",
    "print('\\nResampled class distribution')\n",
    "display(pd.Series(y_train_sm).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e4e75",
   "metadata": {},
   "source": [
    "### Now that our features have been selected, and our data has been upsampled we will go on to scale our data.\n",
    "\n",
    "#### Before we fit our data into any model it is very important that we scale our data since our features do not contain the same degree of values in them, we must scale them so that they are centred at mean = 0 and variance = 1 at the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb27d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a standard scalar to scale our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703f0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the sampled train data and the unsampled test data\n",
    "ss_sm = StandardScaler().fit(X_train_sm)\n",
    "X_train_sm_ss = ss_sm.transform(X_train_sm)\n",
    "X_test_ss = ss_sm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59fcf8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661508704061895\n",
      "0.9324055666003976\n"
     ]
    }
   ],
   "source": [
    "# Instantiate\n",
    "employee_logit = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit\n",
    "employee_logit.fit(X_train_sm_ss, y_train_sm)\n",
    "\n",
    "# Score\n",
    "print(employee_logit.score(X_train_sm_ss, y_train_sm))\n",
    "print(employee_logit.score(X_test_ss, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f6d71",
   "metadata": {},
   "source": [
    "After upsampling the data, the model performed at 97% accuracy on the training data and 93% accuracy on the test data. The model's training accuracy increased by 3 percentage points. These scores are still great, the delta between the two scores is only 3 percentage points and this could be deemed as a great performing model, however, at this point we can not deductively state that this is a great model.\n",
    "\n",
    "We need to further granulate the performance matrics of the model and assess how accurate is is at predicting true positive and true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbf335",
   "metadata": {},
   "source": [
    "### Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a838c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    443\n",
       "1     60\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class distribution\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "975c222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classification\n",
    "y_test_pred = employee_logit.predict(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "940d44b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[434,   9],\n",
       "       [ 25,  35]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate the (raw) confusion matrix:\n",
    "\n",
    "cf_test = confusion_matrix(y_test, y_test_pred)\n",
    "cf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba3f4366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>434</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0          434            9\n",
       "true 1           25           35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = cf_test,\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73313656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "# the function expects the estimator, inputs and target as parameters\n",
    "plot_confusion_matrix(employee_logit, X_test_ss, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2923c",
   "metadata": {},
   "source": [
    "The model predicted 434 True Negatives, 35 True Positives, 25 False Positive and 9 False Negatives. \n",
    "\n",
    "The raw numbers themselves do not tell us much of a comprehensive story behind the performance of our model and so we will generate a classification report that will provide more information about, model precisio, recall, f1-score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4242ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       443\n",
      "           1       0.80      0.58      0.67        60\n",
      "\n",
      "    accuracy                           0.93       503\n",
      "   macro avg       0.87      0.78      0.82       503\n",
      "weighted avg       0.93      0.93      0.93       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cf_test_report = classification_report(y_test, y_test_pred)\n",
    "print(cf_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9a36f",
   "metadata": {},
   "source": [
    "From the unsampled data classification report we observed that the precision rate of the model at predicting attrition is 84% and the recall rate is 53% and f1-score is 65%.\n",
    "\n",
    "From the Upsampled data classification report we observed that the precision rate of the model at predicting attrition is 80% and the recall rate is 58% and f1-score is 67%.\n",
    "\n",
    "We can observe a significant improvement in the recall score from 53% to 58%, this is good for us because the model has become better at detecting attrition overall. The f1-score also improved from 65% to 67% and this is significantly good as our model has moved in the right direction towards lowering the amount of false positives and false negatives.\n",
    "\n",
    "Although the precision score has declined from 84% to 80%, this has occured as a trade off with the improvements in recall and nonetheless 80% is still a good enough precison score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7f0ee",
   "metadata": {},
   "source": [
    "#### In effort to further enchance our model performance we will attempt to optimize our model hyperparameters and evaluate the performance results. In this case, we will be optimizing the Logistic Regression C-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4639fe5",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763bc02",
   "metadata": {},
   "source": [
    "We'll take our train data and split it to create a validation dataset from it. \n",
    "* Train + Validation Sets: 80%\n",
    "* Test Set: 20%\n",
    "\n",
    "Since our test data has been seperated already we will go ahead and split the upsampled train dataset and create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba8018cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the remainder in two chunks\n",
    "X_train_new, X_validation, y_train_new, y_validation = \\\n",
    "    train_test_split(X_train_sm, y_train_sm, test_size = 0.3,\n",
    "                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01e3d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set: (503, 49)\n",
      "Shape of validation set: (621, 49)\n",
      "Shape of train set: (1447, 49)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of test set: {X_test.shape}')\n",
    "print(f'Shape of validation set: {X_validation.shape}')\n",
    "print(f'Shape of train set: {X_train_new.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12538f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the sampled train data and transform the validation data\n",
    "ss_sm2 = StandardScaler().fit(X_train_new)\n",
    "X_train_new_ss = ss_sm2.transform(X_train_new)\n",
    "X_validation_ss = ss_sm2.transform(X_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7693a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tawandanigelchitapi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "train_scores = []\n",
    "\n",
    "C_range = np.array([.00000001,.0000001,.000001,.00001,.0001,.001,0.1,\\\n",
    "                1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000])\n",
    "\n",
    "for c in C_range:\n",
    "    my_logreg = LogisticRegression(C = c,random_state=1)\n",
    "    my_logreg.fit(X_train_new_ss,y_train_new)\n",
    "    \n",
    "    # train on traning set\n",
    "    train_scores.append(my_logreg.score(X_train_new_ss,y_train_new))\n",
    "    # score on validation set\n",
    "    validation_scores.append(my_logreg.score(X_validation_ss,y_validation))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5423081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(C_range, train_scores,label=\"Train Score\",marker='.')\n",
    "plt.plot(C_range, validation_scores,label=\"Validation Scores\",marker='.')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b060ce",
   "metadata": {},
   "source": [
    "From the plot above we can observe that the preferred  optimized c-value is [10^(-1)] or 0.1. At this point our model is not overfitting, the validation score is slightly above the train score. Both the train score and validation score sit at about 93% accuracy. These are significantly high accuracy scores, they  good enough for us to accept and trust our model performance.\n",
    "\n",
    "However, we will now re-model with the preferred c-value and compare the test accuracy scores with the test score of the non-optimized c-value. There after we will re-evaluate the model performance and assess results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85c0cce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324055666003976"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will run our model with the newly identified c-value\n",
    "my_optimized_employee_model = LogisticRegression(C=0.1,random_state=1)\n",
    "\n",
    "# Remember that X_train_sm and y_train_sm held the data I split into train_new and validation\n",
    "# I can use that data to re-train my model\n",
    "my_optimized_employee_model.fit(X_train_sm_ss,y_train_sm)\n",
    "my_optimized_employee_model.score(X_test_ss,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b856e6",
   "metadata": {},
   "source": [
    "Test score has remained at **93% accuracy** after optimizing our c-value, (the logistic regression hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428c593",
   "metadata": {},
   "source": [
    "### Evaluation on Test Data - After optimizing hyperparameter (c-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faf9f411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    443\n",
       "1     60\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class distribution\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8b05017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classification\n",
    "y_test_pred = my_optimized_employee_model.predict(X_test_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82686a",
   "metadata": {},
   "source": [
    "Generate the (raw) confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "422d1222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[435,   8],\n",
       "       [ 26,  34]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_test = confusion_matrix(y_test, y_test_pred)\n",
    "cf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b934f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>435</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0          435            8\n",
       "true 1           26           34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = cf_test,\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76c4d67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaKklEQVR4nO3deZwV9Znv8c+3GxQVVJAlKBqX4K6gQRTNGKJGcYsaNROTzDDqfWnu6GAmmeugZuIWMk6iY+7MuOESuSauUaMxhkiIxCVuiIj7SyIEUQTBBRAN0Dz3j1ONB+g+XQXn9DlV/X3nVa8+VaeWh0ae/Kp+9fs9igjMzIqoqd4BmJnVihOcmRWWE5yZFZYTnJkVlhOcmRVWt3oHUK6HFL2cc3Pls/vsXe8QLIPZc+awcOEibcg5tlW3+IR0b18sZNXvImLUhlxvQzRUgutFEyeyab3DsAyufWxKvUOwDIZ9YeQGn+OvBCezWap9r2FJ3w2+4AZoqARnZvnQpJSNwDq/ZusEZ2aZiPw8vHeCM7PMmtI+xXMLzszyRIhuaW9R68wJzswy8y2qmRWSyHCLWmdOcGaWmVtwZlZMAvkZnJkVkV8TMbNC65aPBpwTnJllU+pkyEeGc4Izs8x8i2pmhZSn10TykojNrIE0pVzSkNQs6TlJDyTrfSRNkvR68rN32b7nSZop6TVJR6SJ08wsNQHdpFRLSucAr5StjwUmR8RgYHKyjqTdga8DewCjgKslNVc6sROcmWVWrRacpEHA0cANZZuPAyYknycAx5dtvz0i/hoRs4CZwPCO4jQzS00qPYNLswB9JU0tW85Y63Q/Bc4FVpVtGxAR8wCSn/2T7dsAb5btNzfZ1i53MphZZk2kvv1cGBHD2vpC0jHAgoh4VtLIFOdq66IVJ2RygjOzzKrUi3oQ8BVJRwE9gM0l/RyYL2lgRMyTNBBYkOw/F9i27PhBwNsV46xKmGbWZbQO1drQZ3ARcV5EDIqI7Sl1HvwhIr4F3A+MTnYbDdyXfL4f+LqkjSXtAAwGnq50DbfgzCyTTpjw8jLgTkmnA3OAkwEi4iVJdwIvAyuBsyKipdKJnODMLLNqv+gbEVOAKcnnRcCh7ew3DhiX9rxOcGaWWU4GMjjBmVk2eRqq5QRnZplleE2krpzgzCwTyS04MyuwigNAG4gTnJll4gkvzazQ8pHenODMbD04wZlZYTnBmVkh+RmcmRVaXmbpcIIzs8xy0oBzgjOz7JSTp3BOcGaWiXAng5kVmBOcmRWUaM7JQ7i8dIaYWYNQhqXieaQekp6W9LyklyRdnGy/SNJbkqYny1Flx2Qq/OwWnJllo6r1ov4VOCQilkrqDjwm6bfJd1dGxOVrXHbNws9bA7+XtHOlacvdgjOzzKrRgouSpclq92SpVAbQhZ/NrPaaUKqlI5KaJU2nVBpwUkQ8lXx1tqQZkm6S1DvZlrnwsxOcmWWS8Rlcxcr2EdESEUMp1TgdLmlP4BpgJ2AoMA+4ouzSa3PhZzOrrgwz+rZb2b5cRHwgaQowqvzZm6TrgQeSVRd+NrPaU8r/VTyH1E/SlsnnTYDDgFeTavatTgBeTD678LOZ1VYVq2oNBCZIaqbU2LozIh6QdIukoZRuP2cDZ4ILP5tZJ6lGfouIGcA+bWz/uwrHuPCzmdVWPsYxOMGZ2XrwhJddjJqaOO+xB/ng7Xe4+qR/4Nh/+xeGHHMEsWoVS95dyIQzvsuH78xnq+0GceG0Kcx//c8AzHp6Greec16do7dWv//v63l8wu0I2HqPXRl93RV079Gj3mE1FJGf3smaxilpVDJmbKaksbW8Vr0dctbpvPPazNXrk356LT/c/8uMG3EEL/x2Mkef953V3707azbjRhzBuBFHOLk1kPffnsfD1/yM8x59gB9MncyqVat45q776x1WQ6rGSIbOULMEl/SMXAUcCewOnJKMJSucLbceyF6jDuXxm29dve2TJUtXf95os02IqPg+ojWIVStXsuLjT2hZuZIVyz5my4ED6h1SQ5KUaqm3Wt6iDgdmRsQbAJJupzSW7OUaXrMuvvbji7jngnH06NVzje3HXXgu+3/jJD5evJgrj/za6u19P7sd5/9pIp8sXsr9l/yYmX+q+CqPdZLeWw/ksHPO5PxdD6D7Jj3Y7ZCD2f2wL9Y7rIZU/9SVTi1vUVONG5N0Ruswjk8qj7poSHuNOpQl7y5kzvQX1vnuvot/zPm7DOfpO+5l5JmnAvDhOws4f9fh/OjAUfxy7MWc9rP/WScxWn189P4HzHjgIX740p/4j5lTWb5sGU/ddk+9w2o41ZouqTPUMsGlGjcWEeMjYlhEDOvREL+SbHYasR97H304415+gtMnXMWuXzyIU2/8rzX2eeaOX7HP8UcCsHL5cj567wMA5kx/gYVv/IX+n9uxs8O2Nrz68GNstf229Oq3Fc3du7PPV47kz09NrXdYjUeiuSndUm+1THCZx43l0a8uvIzzdt6PC3YfwY2jz+LVPz7Oz04fQ/+ddli9z95HH87810q9pj379kFNpV973+23o//ndmDh7Dl1id3W1GfbbZj1zHMsX/YxEcGrUx5n4C6D6x1WQ1KTUi31VstncM8Ag5MxY29RmqjuGzW8XkM5/pLzGLDzjsSq4L05c7l1TKm3dPBBB3Ds97/HqpYWVrW08IsxY1n2/gf1DdYA2GG/fdj3+KMYd9CRNDc3s+2QPfnCaV3mP9nURH7KBqqWvXvJVMM/BZqBm5JhFu3qp+Y4kU1rFo9V37Ufza13CJbBsC+MZOq05zYoPe2x8cZx22cGdrwjMGTOX55NM5tIrdT0Rd+IeBB4sJbXMLPO1wivgKThkQxmlllO8psTnJllI6CpAToQ0nCCM7Ns5MH2ZlZgOclvTnBmllVjjDNNIy+znphZgxCgpnRLxfO0X9m+j6RJkl5PfvYuOyZTZXsnODPLRqVOhjRLB1or2w+hVCJwlKQDgLHA5IgYDExO1teubD8KuDqZtahdTnBmllk1pkuqUNn+OGBCsn0CcHzy2ZXtzaz2pHQLHRR+bqey/YCImAeQ/Oyf7J65sr07Gcwsk1LZwNSdDBULPydl/4Ym9VHvTSrbV7r0OqeodHG34Mwsm5SttywdrRHxATCF0rO1+a3Fn5OfC5LdXNnezGqvGs/g2qtsT6mC/ehkt9HAfclnV7Y3s9oqDdWqyqnaq2z/BHCnpNOBOcDJ4Mr2ZtYZVJ3JLCtUtl8EHNrOMa5sb2a1lZOBDE5wZpadB9ubWSHlacpyJzgzyywvg+2d4MwsG3nCSzMrsJw04JzgzCyb0jO4fGQ4Jzgzy0Ydz/XWKJzgzCyj/Mzo6wRnZtk156MJ5wRnZtnIz+DMrMjy/pqIpP+mwmRyETGmJhGZWYPLONlbHVVqwU3ttCjMLDckqjKbSGdoN8FFxITydUmbRcRHtQ/JzBpeTlpwHXaFSBoh6WXglWR9iKSrax6ZmTUsNTelWuotTQQ/BY4AFgFExPPAwTWMycwamVTqZEizVDyNtpX0sKRXksLP5yTbL5L0lqTpyXJU2TGZCj+n6kWNiDfX6hauOE2wmRVblV4TWQl8LyKmSeoFPCtpUvLdlRFx+VrXLC/8vDXwe0k7V5q2PE2Ce1PSgUBI2ggYQ3K7amZdVHWmLJ8HtNY/XSLpFSrXOV1d+BmYJam18PMT7YaZIo5vA2clF34LGJqsm1lX1DrjZRXrBkranlJ9hqeSTWdLmiHpJkm9k22ZCz93mOAiYmFEfDMiBkREv4j4VlIUwsy6KDUr1UIHle0BJPUE7ga+ExGLgWuAnSg1puYBV7Tu2kYoFQs/d3iLKmlH4P8CByQnewL454h4o6NjzayAslXVqljZXlJ3SsntFxFxD0BEzC/7/nrggWS1JoWfbwXupFTDcGvgLuC2FMeZWVFV4RZVpZ6KG4FXIuI/y7YPLNvtBODF5HNNCj8rIm4pW/+5pLNTHGdmRVWdkQwHAX8HvCBperLtfOAUSUMp3THOBs6EKhd+ltQn+fiwpLHA7ckF/xb4zfr9ecws71Sl2UQi4jHafq72YIVjqlb4+VlKCa01gDPLrwNcmvYiZlYwBRiLukNnBmJmeSHUVP9hWGmkGskgaU9gd6BH67aI+H+1CsrMGpjIfwuulaQLgZGUEtyDwJHAY4ATnFkXlZcZfdO0M08CDgXeiYhTgSHAxjWNyswaWxUG23eGNLeoH0fEKkkrJW0OLAB2rHFcZtaoMg7Dqqc0CW6qpC2B6yn1rC6lg5frzKzYcj+jb6uI+Mfk47WSJgKbR8SM2oZlZg1L5L9soKR9K30XEdNqE5KZNbq8dDJUasFdUeG7AA6pcix8duieXPOHidU+rdVQLPuw3iFYFquqMVdtY3QgpFHpRd8vdWYgZpYjBWjBmZmtq3XCyxxwgjOzjATNzfUOIhUnODPLLictuDR1USXpW5J+kKxvJ2l47UMzs4ZUg5oMtZLmZZargRHAKcn6EuCqmkVkZo0vJwkuzS3q/hGxr6TnACLi/aR8oJl1SYKcTJeUJsoVkppJqtdI6gesqmlUZtbYqlOTob3K9n0kTZL0evKzd9kxmSrbp0lw/wXcC/SXNI7SVEk/SnGcmRWRKLXg0iyVtVa2341S1b6zkur1Y4HJETEYmJysr13ZfhRwddL4aleasai/kPQspSmTBBwfEa5sb9ZlVecWtUJl++MozUEJMAGYAvwr61HZPs2El9sBy4Bfl2+LiDnZ/0hmVgjpOxD6Sppatj4+Isave7o1KtsPSJIfETFPUv9kt22AJ8sO67CyfZpOht/wafGZHsAOwGuUmolm1tVkG8lQsfAzrFvZvsJA/upXto+IvdYKZl/WrLBlZl1NlV4BaauyPTBf0sCk9TaQ0iS7UKPK9mtIpknaL+txZlYMSqpqpVkqnqedyvaUKtiPTj6PBu4r217dyvaSvlu22gTsC7zb0XFmVlCtvagbrr3K9pcBd0o6HZgDnAxVrmxfplfZ55WUnsndneEPYWZFU9vK9lB6a6OtY6pW2Z7kHZOeEfF/0p7QzIouPyMZKk1Z3i0iVlaautzMuqgGGGeaRqUW3NOUnrdNl3Q/cBfwUeuXZT0eZtaVFGzCyz7AIko1GFrfhwvACc6sSyrGhJf9kx7UF/k0sbWq+HKdmRVcAVpwzUBP1uPtYTMrsILcos6LiEs6LRIzy4kC9KLS/vspZtbVFaAF1+aLdmZmuU9wEfFeZwZiZjmhYvSimpm1Le8tODOzdjnBmVkhCVD+e1HNzNogaHILzsyKyi04MyukHPWi5iMNm1ljqULh59JpdJOkBZJeLNt2kaS3JE1PlqPKvqt64WczszWpKd3SsZspFXFe25URMTRZHoT1K/zsBGdm2VWpBRcRjwBpBxWsLvwcEbOA1sLP7XKCM7NslAy2T7MkhZ/LljNSXuVsSTOSW9jeybZtgDfL9qlK4WczszU1pe5k6LDwcxuuAS6lNC3bpcAVwGnUovCzmdkaVNv34CJi/qeX0vXAA8lq7Qs/m5lVsZNh3VOXqtm3OoHSrOJQi8LPZmbrqNJYVEm3ASMpPaubC1wIjJQ0lNLt52zgTKhd4WczszKq2kiGiDiljc03Vti/eoWfzczWITwW1cwKLH0val05wZlZNjXuRa0mJzgzy86ziZhZYXlGXzMrpur1otaaE5yZZSNyMx+cE5yZZedb1K7nvbnzmPCP57J4/kLU1MQXRn+NQ749GoCHx9/ClBt+TnNzN/Y8/It89eJz6xytAaz45K9c8ZXRrFy+nFUrW9jn2C9z7L+evfr7SVf9jHsuuoKfvPooPbfqXeFMXYlaZwppeDVLcJJuAo4BFkTEnrW6TiNp7tbMiZeOZbshe/DJkqX8+yEnstvIg1j87kKe/+1kvv/or+m+8UYsfndRvUO1RLeNN+I799xEj56b0rJiBZcf8/fscejfsOOwIbz31jxemfIEfQYN7PhEXYnITQuulmn4ZtqeqbOwtvhMf7YbsgcAPXr15DM778gH8+bzyE23ccQ5Z9B9440A2LzfVvUM08pIokfPTQFoWbGSlhUrUfKP95ff/zFfvfC7ufnH3KlqONi+mmoWQcaZOgtn0Zy5vDnjFbb//BAW/Hk2M5+Yyn8cdjL/ecy3mD1tRr3DszKrWloYN/JEzt3tYHYbOYIdPr83z098mC0H9mfQnrvWO7wGlHI23wb4P4a6P4NLZvg8A2C7QRUn58yNT5Z+xHWjx3Dyj85nk8170rKyhWUfLubcSXfyl2kvcMNp3+HS5yavbilYfTU1N3PBlLtZ9uFirht9DnNfeo2JV45nzF3j6x1aY8pRL2rd25ARMT4ihkXEsH5983/r1rJiBeNHj2H4Sceyz7GHA9B76wHsc8yXkcT2n98bNTWxdNH7dY7U1rbpFpsz+KD9mDHxYRbOeYsfjjyRC/Y9nA/ens+PDj2ZD+cvrHeIDUK5uUWtewuuSCKCW8ZcwGd23pHDzjp19fYhRx/Ga488yc5f2J/5M2fRsnyFe+QaxJKF79HcvRubbrE5yz/+hFf/+CRHjDmNn7zyyOp9Ltj3cM6bdIf/zsrl5O7DCa6K/vzUszx1x31ss/vOjDv4OACO+7fvcuA3T+SWfzqfSw48hm4bdefvr77Mt6cN4sP57zLh7AuIVS2sWhV8/rgj2OvwkfUOq/E1QOssjVq+JrLOTJ0R0e5EdkXwuQOGcc17r7X53anXXd7J0Vgag/bYhQse/mXFfcZNe6iTosmJHM0mUste1FMiYmBEdI+IQUVPbmZdSpWewbVT2b6PpEmSXk9+9i77zpXtzayWVJrwMs3SsZtZ933ZscDkiBgMTE7WXdnezDqHpFRLR9p5X/Y4YELyeQJwfNn2TJXt3clgZtmILJ0MfSVNLVsfHxEdvWA4ICLmAUTEPEn9k+3bAE+W7efK9mZWbZnmg1ufyvYVLryOipXtfYtqZtk1Kd2yfua3Fn9Ofi5ItruyvZnVmKhmJ0Nb7gdGJ59HA/eVbXdlezOrpepNWd5OZfvLgDslnQ7MAU4GV7Y3s85SpZE47VS2Bzi0nf1d2d7MaqyrD9Uys4LK0VAtJzgzy84tODMrJm1ID2mncoIzs+xyMt2XE5yZZZNtqFZdOcGZWUaui2pmBZaXGamd4MwsO9+imlkhyb2oZlZkvkU1s8JyJ4OZFZLkFpyZFZg7GcyssJzgzKyYfItqZkVWpQQnaTawBGgBVkbEMEl9gDuA7YHZwNci4v31OX8+2plm1mCUcknlSxExtKz6VpuFn9eHE5yZZSM+7UntaFk/7RV+zswJzsyyS9+A6ytpatlyxlpnCuAhSc+WfbdG4WegP+vJz+DMLKOqFn4+KCLeTqrXT5L06obH9ym34MwsuyrdokbE28nPBcC9wHDaL/ycmROcma2HDe9kkLSZpF6tn4HDgRdpv/BzZr5FNbPsqvOayADg3mRuuW7ArRExUdIztFH4eX04wZnZetjwBBcRbwBD2ti+iHYKP2flBGdm2XiwvZkVmseimllRuSaDmRWXE5yZFVOmcaZ15QRnZtm5BWdmheTK9mZWaG7BmVlh5SO/OcGZWVbuZDCzIvMtqpkVUuuMvjngBGdm2bkX1cyKyYPtzazQnODMrKhy0oJTRNQ7htUkvQv8pd5x1EBfYGG9g7BMivp39tmI6LchJ5A0kdLvJ42FETFqQ663IRoqwRWVpKkdVBayBuO/s2LIR1eImdl6cIIzs8Jygusc4+sdgGXmv7MC8DM4Mysst+DMrLCc4MyssJzgakjSKEmvSZopaWy947GOSbpJ0gJJL9Y7FttwTnA1IqkZuAo4EtgdOEXS7vWNylK4Gajbi6lWXU5wtTMcmBkRb0TEcuB24Lg6x2QdiIhHgPfqHYdVhxNc7WwDvFm2PjfZZmadxAmudtoajex3csw6kRNc7cwFti1bHwS8XadYzLokJ7jaeQYYLGkHSRsBXwfur3NMZl2KE1yNRMRK4Gzgd8ArwJ0R8VJ9o7KOSLoNeALYRdJcSafXOyZbfx6qZWaF5RacmRWWE5yZFZYTnJkVlhOcmRWWE5yZFZYTXI5IapE0XdKLku6StOkGnOtmSScln2+oNBGApJGSDlyPa8yWtE71pfa2r7XP0ozXukjSv2SN0YrNCS5fPo6IoRGxJ7Ac+Hb5l8kMJplFxP+KiJcr7DISyJzgzOrNCS6/HgU+l7SuHpZ0K/CCpGZJP5H0jKQZks4EUMn/SHpZ0m+A/q0nkjRF0rDk8yhJ0yQ9L2mypO0pJdJ/TlqPfyOpn6S7k2s8I+mg5NitJD0k6TlJ15Gi/LmkX0l6VtJLks5Y67srklgmS+qXbNtJ0sTkmEcl7VqV36YVkivb55CkbpTmmZuYbBoO7BkRs5Ik8WFE7CdpY+BxSQ8B+wC7AHsBA4CXgZvWOm8/4Hrg4ORcfSLiPUnXAksj4vJkv1uBKyPiMUnbURqtsRtwIfBYRFwi6WhgjYTVjtOSa2wCPCPp7ohYBGwGTIuI70n6QXLusykVg/l2RLwuaX/gauCQ9fg1WhfgBJcvm0iannx+FLiR0q3j0xExK9l+OLB36/M1YAtgMHAwcFtEtABvS/pDG+c/AHik9VwR0d68aIcBu0urG2ibS+qVXOOrybG/kfR+ij/TGEknJJ+3TWJdBKwC7ki2/xy4R1LP5M97V9m1N05xDeuinODy5eOIGFq+IfmH/lH5JuCfIuJ3a+13FB1P16QU+0Dp0caIiPi4jVhSj/2TNJJSshwREcskTQF6tLN7JNf9YO3fgVl7/AyueH4H/G9J3QEk7SxpM+AR4OvJM7qBwJfaOPYJ4IuSdkiO7ZNsXwL0KtvvIUq3iyT7DU0+PgJ8M9l2JNC7g1i3AN5PktuulFqQrZqA1lboNyjd+i4GZkk6ObmGJA3p4BrWhTnBFc8NlJ6vTUsKp1xHqaV+L/A68AJwDfDHtQ+MiHcpPTe7R9LzfHqL+GvghNZOBmAMMCzpxHiZT3tzLwYOljSN0q3ynA5inQh0kzQDuBR4suy7j4A9JD1L6RnbJcn2bwKnJ/G9hKeBtwo8m4iZFZZbcGZWWE5wZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWP8foCB5tifgRkYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function expects the estimator, inputs and target as parameters\n",
    "plot_confusion_matrix(my_optimized_employee_model, X_test_ss, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c4ac9",
   "metadata": {},
   "source": [
    "The model predicted 435 True Negatives, 34 True Positives, 26 False Positive and 8 False Negatives. \n",
    "\n",
    "The raw numbers themselves do not tell us much of a comprehensive story behind the performance of our model and so we will generate a classification report that will provide more information about, model precisio, recall, f1-score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aad75257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       443\n",
      "           1       0.81      0.57      0.67        60\n",
      "\n",
      "    accuracy                           0.93       503\n",
      "   macro avg       0.88      0.77      0.81       503\n",
      "weighted avg       0.93      0.93      0.93       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "cf_test_report = classification_report(y_test, y_test_pred)\n",
    "print(cf_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244f269",
   "metadata": {},
   "source": [
    "From the Upsampled data classification report we observed that the precision rate of the model at predicting attrition is 80% and the recall rate is 58% and f1-score is 67%.\n",
    "\n",
    "After optimizing the hyperparameter c-value, the precision score has increase by 1% point from 80% to 81%, the recall score has decreased by 1 percentage point from 58% to 57% and the f1-score has remained the same at 67%.\n",
    "\n",
    "With an increase in precision score and a decrease in recall score the f1-score which is the harmonic mean of the precision and recall scores has remained the same at 67%, the model is still performing really well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff8ff5",
   "metadata": {},
   "source": [
    "#### We will attempt one more method to optimize hyperparameters, we will employ a pipeline grid search and which will yeaild the best hyperparameter values to use in our model. After yeilding the best estimators, we will re-model our data and evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccbe369",
   "metadata": {},
   "source": [
    "### Now we wil employ a pipeline GridSearch to determine the best estimators and prevailing parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de581166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23c19c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 440 candidates, totalling 2200 fits\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.896 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.954 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.910 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.864 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.843 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.954 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=Logist[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_icRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.872 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.954 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.911 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.499 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.910 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.795 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.501 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.957 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.954 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.768 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.954 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.894 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.901 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.879 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.918 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.886 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.795 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.932 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.939 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.928 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.896 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.896 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.877 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.864 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.899 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.823 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.765 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.925 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.928 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.910 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.928 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.935 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.942 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.811 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.768 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.790 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.826 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.957 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.935 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.927 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.944 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.947 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.935 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.879 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.864 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.915 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.763 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.942 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.942 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.910 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.896 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.930 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.913 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.756 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.930 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.954 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.932 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.971 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.928 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.903 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.935 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.932 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.952 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.942 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=MinMaxScaler();, score=0.923 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.775 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.935 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.930 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=7, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.949 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.957 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.915 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.957 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.954 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.773 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.935 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.957 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.939 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=MinMaxScaler();, score=0.932 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.942 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.766 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.947 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=9, scaling=StandardScaler();, score=0.927 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.754 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.949 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.954 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=MinMaxScaler();, score=0.973 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.811 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.877 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.872 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.882 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.862 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.768 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.952 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=10, scaling=StandardScaler();, score=0.923 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=MinMaxScaler();, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.937 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=MinMaxScaler();, score=0.930 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=8, scaling=StandardScaler();, score=0.930 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=5, scaling=StandardScaler();, score=0.898 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=6, scaling=MinMaxScaler();, score=0.923 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=100000.0, model__penalty=l1, model__random_state=1, model__solver=liblinear, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.872 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.831 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1e-05, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.0001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=StandardScaler();, score=0.783 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.908 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.758 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=4, scaling=MinMaxScaler();, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.761 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=StandardScaler();, score=0.920 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.751 total time=   0.1s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.845 total time=   0.1s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.870 total time=   0.1s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=1.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=3, scaling=MinMaxScaler();, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.867 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=MinMaxScaler();, score=0.845 total time=   0.0s\n",
      "[CV 1/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END model=LogisticRegression(), model__C=10.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=2, scaling=StandardScaler();, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END model=LogisticRegression(), model__C=100.0, model__penalty=l2, model__random_state=1, model__solver=lbfgs, reduce_dim=PCA(), reduce_dim__n_components=1, scaling=StandardScaler();, score=0.831 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# estimators\n",
    "# note that all the planned steps must be included, but the second elements in each tuple are more like placeholders\n",
    "estimators = [\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "]\n",
    "\n",
    "# instantiate pipeline with the specified steps\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# define parameter grid\n",
    "param_grid = [\n",
    "    \n",
    "    # logistic regression with L1 regularization\n",
    "    {\n",
    "        'scaling': [MinMaxScaler(), StandardScaler()],\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'model': [LogisticRegression()],\n",
    "        'model__penalty': ['l1'],\n",
    "        'model__solver': ['liblinear'],\n",
    "        'model__C': np.logspace(-5, 5, 11),\n",
    "        'model__random_state': [1]\n",
    "    },\n",
    "    \n",
    "    # logistic regression with L2 penalty\n",
    "    {\n",
    "        'scaling': [MinMaxScaler(), StandardScaler()],\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': [1, 2, 3, 4, 5,6, 7, 8, 9, 10],\n",
    "        'model': [LogisticRegression()],\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs'],\n",
    "        'model__C': np.logspace(-5, 5, 11),\n",
    "        'model__random_state': [1]\n",
    "    }\n",
    "]\n",
    "\n",
    "# instantiate cross-validated grid search object with the steps and parameter grid\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = 5,\n",
    "    verbose = 5,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# fit the grid to the unprocessed training data\n",
    "grid.fit(X_train_sm, y_train_sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce8496d",
   "metadata": {},
   "source": [
    "After fitting the grid to the training data, use the `best_estimator_` attribute on your grid search object to obtain the most optimal model and its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "242be687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaling', MinMaxScaler()),\n",
       "                ('reduce_dim', PCA(n_components=10)),\n",
       "                ('model', LogisticRegression(C=0.1, random_state=1))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the most optimal model\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e09e3c",
   "metadata": {},
   "source": [
    "The best estimator recommended to us requires us to the MinMaxScaler, perform dimension reduction 10 components, using logistric regression with a c-value of 0.1 and a random state of 1.\n",
    "\n",
    "We will now implement these recommendations and evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1268c8",
   "metadata": {},
   "source": [
    "### Now using our best estimator we will re-run our model with the specified parameters and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93777345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# 2. make a scaler & fit\n",
    "my_minmax_scaler = MinMaxScaler().fit(X_train_sm)\n",
    "\n",
    "\n",
    "# transfor the scaler\n",
    "X_train_sm_sc = my_minmax_scaler.transform(X_train_sm)\n",
    "X_test_sc = my_minmax_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "422e6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit\n",
    "my_PCA = PCA(n_components = 10)\n",
    "my_PCA.fit(X_train_sm_sc)\n",
    "\n",
    "# Transform train and test\n",
    "X_train_PCA = my_PCA.transform(X_train_sm_sc)\n",
    "X_test_PCA = my_PCA.transform(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f94eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005964214711729"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_employee_model = LogisticRegression(C=0.1,random_state=1)\n",
    "\n",
    "# Remember that X_train_sm and y_train_sm held the data I split into train_new and validation\n",
    "# I can use that data to re-train my model\n",
    "my_final_employee_model.fit(X_train_PCA,y_train_sm)\n",
    "my_final_employee_model.score(X_test_PCA,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4e210",
   "metadata": {},
   "source": [
    "The test score is 90% which is 3 percentage points from our previous 93% score that we got when we manually optimized the c-value hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2227d",
   "metadata": {},
   "source": [
    "### Evaluation on Test Data - After determing the best estimators and fitting the parameters in the Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3bf90c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    443\n",
       "1     60\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class distribution\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c646006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classification\n",
    "y_test_pred = my_final_employee_model.predict(X_test_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab71f6",
   "metadata": {},
   "source": [
    "Generate the (raw) confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5b2e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[424,  19],\n",
       "       [ 31,  29]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_test = confusion_matrix(y_test, y_test_pred)\n",
    "cf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6b28020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true 0</th>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true 1</th>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted 0  predicted 1\n",
       "true 0          424           19\n",
       "true 1           31           29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conmat = pd.DataFrame(\n",
    "    data = cf_test,\n",
    "    index = ['true 0', 'true 1'],\n",
    "    columns = ['predicted 0', 'predicted 1']\n",
    ")\n",
    "display(conmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "300ec2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function expects the estimator, inputs and target as parameters\n",
    "plot_confusion_matrix(my_final_employee_model, X_test_PCA, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f449a3",
   "metadata": {},
   "source": [
    "The model predicted 424 True Negatives, 29 True Positives, 31 False Positive and 19 False Negatives. \n",
    "\n",
    "This model yielded an increased number false positive and false negatives, the amount of true positive decreased.\n",
    "\n",
    "The raw numbers themselves do not tell us much of a comprehensive story behind the performance of our model and so we will generate a classification report that will provide more information about, model precisio, recall, f1-score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b15df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       443\n",
      "           1       0.60      0.48      0.54        60\n",
      "\n",
      "    accuracy                           0.90       503\n",
      "   macro avg       0.77      0.72      0.74       503\n",
      "weighted avg       0.89      0.90      0.90       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "cf_test_report = classification_report(y_test, y_test_pred)\n",
    "print(cf_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1296325",
   "metadata": {},
   "source": [
    "After optimizing the hyperparameters using a pipeline GridSearch, the precision rate fell from 81% to 60%, the recall score fell from 57% to 48% and the f1-score fell from 67% down to 54%.\n",
    "\n",
    "Judging from the results, this optimazation performed worse than our manual optimization and with that, we will stick to the previous model, as it performs better.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63284b24",
   "metadata": {},
   "source": [
    "This model will end here, Another model, the Decision tree model will be applied in a different notebook and results will be compared in order to decide which model best predicts employee attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c9e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
